### 这是一个基于客户现场物料区的萤石云摄像头的算法预警系统。
<mark> NOTE: 这是一个很早期的小demo，请勿用于生产环境。</mark>

#### 系统概述
- 分布式集群：检测系统运行在一个分布式集群中，集群中的每个节点负责处理不同的任务。这些节点位于内网环境中，无法直接从外网访问。
- 负载均衡：在同一个节点上部署了四个容器，每个容器配置了 16 核 CPU 和 A4000 GPU，用于处理高并发请求。这些容器通过fastapi实现负载均衡器分发来自数据层的数据，确保系统的高可用性和性能。
- 萤石云：萤石云是海康提供视频监控服务的平台，用于远程访问摄像头数据。它位于外网，用户可以通过互联网访问萤石云服务器的摄像头数据(无法直接访问到摄像头的视频流)
- 控制层：控制层是整个系统的入口点，负责对接萤石云提供的API，并采集来自外网的萤石云的图像数据，并将这些数据转发到内网中的分布式集群节点进行处理。
由于内网节点只有一个外网 IP，因此需要通过某种方式将外网请求路由到内网中的不同节点。
- 算法层：算法层负责接收来自控制层的图像数据，并进行人员入侵、人走门未关、摄像头遮挡检测。它使用线程池来处理图像数据，以实现高并发处理。

#### 项目介绍
- 1、数据层： 摄像头的采集数据，使用rtsp协议采集，存储在minio中。(java后端同事做的)
- 2、控制层： 基于fastapi接受数据层实时分发的图像地址。并转发到算法服务层。
- 3、算法层： 基于fastapi接受分发的图像数据,使用线程池解耦取图和推理, 目前三个算法都是基于yolov5和opencv实现的检测功能。
- 4、事件层： 后处理算法检测结果，并将事件结果的回放时间回传到数据层，并转发到前端提供的API。
- 5、记录层： 存储事件结果的日志和违规图片。


#### 项目过程的问题点
- 1、控制层： 系统架构在了分布式集群的一个节点上, 负载均衡在四个16核+A4000的容器上, 但是分布式集群的节点在内网,
而萤石云在外网, 只有节点只有一个外网IP, 所以需要将数据层和算法层通过nginx代理到控制层，。TODO

- 2、算法层： 算法层原先的fps能够达到15帧,后来细化解耦取图和推理的步骤，将网络取图和推理做异步处理，中间使用队列传输，提高并发处理能力。
但是会增加内存的消耗。现在生产环境中，算法层fps已经超过30帧。超出摄像头的25帧。需要细腻的调节队列的大小和线程池的线程数。
- 3、事件层： 事件层需要将事件结果回传到数据层，但是采图取图会有网络延时，将时间戳回传到数据层，数据层根据时间戳进行回放。
前期的使用中经常会出现 回放对应不是真实的事件, 且内网的时间和外网的时间也对不上。
第一版解决方案通过把图像的采集时间戳作为文件名，通过文件名进行排序，但是由于图像采集的萤石云服务器的数据和摄像头的数据不是实时的，所以排序后还是存在时间上的偏差。
第二版解决方案是使用OCR识别图像中的时间，但是时间开销较大。
最终落地的解决方案是把事件报警的图像地址回传到数据层拼接回放录像，并与事件报警的主键id进行关联， 数据层发送到前端，前段再根据id到外网节点提供的API查询报警类型，进行回放展示。
- 4、流量优化：萤石云回放服务按照播放回放的流量收费，为了节省月度会员的流量开销，所以需要改为摄像头改为事件模式, 摄像头服务器只保存报警回放。
算法报警回放由拼接的回放处理。第三层的优化正好解决了这个问题。


#### 优化点
- 1、优化算法层和事件层：每个容器的算法推理将作为独立的微服务, 通过gunicorn+fastapi提高算法推理的并发能力和稳定性。
- 2、算法层和数据层通过Kafka实现解耦,减少网络的请求，提升系统的吞吐量。
- 3、数据层生产图像消息，算法层消费图像消息，事件层生产结果消息，数据层消费结果消息。 